+++
# Date this page was created.
date = "2016-04-27"

# Project title.
title = "Trust and Feedback in HRI"

# Project summary to display on homepage.
#summary = "An example of linking directly to an external project website using `external_link`."

# Optional image to display on homepage (relative to `static/img/` folder).
image_preview = "trustNew.jpg"

# Tags: can be used for filtering projects.
# Example: `tags = ["machine-learning", "deep-learning"]`
tags = ["hri"]

# Optional external URL for project (replaces project detail page).
#external_link = "http://example.org"

# Does the project detail page use math formatting?
math = false

+++

Started this project during Summer, 17 at the Robotics Lab, University of Massachusetts Lowell under Prof. Holly Yanco. The aim of the project is to understand the effect of using different feedback strategies, on Real-Time Trust of an operator, during Human-Robot Collaborative tasks. We designed an HRI experiment using an iRobot Atrv robot. In the experiment, the participants were to remotely supervise a robot doing a pre-defined navigation task, using an interactive GUI. Using the results of this empirical study, we aim to come up with a feedback strategy that ensures proper calibration of trust in the automation system, at the same time, improves performance and reduces operator workload. The results of this study are useful for many human‐in‐the‐loop autonomous systems like self‐driving cars, UGVs, autopilot systems, etc. 